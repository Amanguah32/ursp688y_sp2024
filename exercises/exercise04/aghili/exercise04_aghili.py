# -*- coding: utf-8 -*-
"""exercise04_aghili.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/121Tjjdzacu48LVJkLqsq1FM4SPxcYSUY

Urban Data Science & Smart Cities <br>
URSP688Y <br>
Instructor: Chester Harvey <br>
Urban Studies & Planning <br>
National Center for Smart Growth <br>
University of Maryland

[<img src="https://colab.research.google.com/assets/colab-badge.svg">](https://colab.research.google.com/github/ncsg/ursp688y_sp2024/blob/main/exercises/exercise04/exercise04.ipynb)

# Exercise 4 (in Two Parts)

# The Data Viz Part

Next week is Data Visualization week. This is one of my favorite topics, in part because we get to look at lots of pictures, and in part because it provides an excuse for some very lighthearted competition.

In prep for next week, part of your exercise is to find an example of either an _excellent_ or _terrible_ data visualization. We will vote on the best (and worst) in each category, and the winner gets a small (tasty) prize.

Please find an example of a data visualization that is either _very effective_ or _terribly ineffective_ in communicating an interesting finding from data. Here are a few ground rules:
- One figure only: We should be able to see the whole thing at once on a projector screen.
- Static images only: If you find something dynamic or interactive that you _must_ submit, please take a screenshot.
- Do the reading first: Tufte will give you some ideas for what makes visualizations good or bad
- No examples from Tufte. Gotta work a little bit.

Please either paste a link to your image in the text cell below (can you figure out how to get markdown to display the image?) or add an image file to your PR.
- Please label it clearly as "good" or "bad" so we know which race you're in.
- Please write a couple bullets about why it's good or bad. This is your pitch (we can haggle about it in class, too.)

## Good/Bad (please choose one and delete the other)
Bad https://www.colorado.edu/geography/sites/default/files/styles/medium/public/article-image/capture1.png?itok=PzfEgLIn
- Why
It has too many labels

***** Put image link or insert image here *****

# The Programming Part

## Problem

In [Exercise 3](https://github.com/ncsg/ursp688y_sp2024/blob/main/exercises/exercise03/exercise03.ipynb), you examined how many affordable housing units available to households up to 60% AMI were planned within each ward in Washington, D.C.

The bonus problem was to calculate which wards were producing a _disproportionately_ large and small number of housing units given their populations.

This week, please reproduce this analysis, <ins>including</ins> the bonus part, using some of your new data loading, joining, and module-building skills.

Please write a program that:

- Loads the affordable housing project data from `affordable_housing.csv`
- Loads the ward populations from `wards_from_2022.csv`
- Joins the population data to the affordable housing data
- Calculates which wards are producing disproportionately large and small number of housing units given their populations
- Completes all of this data loading and processing within a function (or a series of functions called by a single main function)
- Stores that function (and any related functions) in a module
- Calls the main function in the exercise notebook to return table or other summary or results

## Data

CSVs for both required data tables are included on GitHub at `exercises/exercise04`.

Please consult the city's database of [affordable housing](https://opendata.dc.gov/datasets/DCGIS::affordable-housing/about) projects and [ward demographic](https://opendata.dc.gov/datasets/DCGIS::wards-from-2022/about) data.

Bonus: find, download, and use more recent ward population data. (Remember to include it in your PR.) My cursory search found data as late as 2022.

## New instructions for submitting a PR with multiple files

Because you'll be working with multiple files, PRs become _slightly_ more complicated, so we're graduating to a new 'mini-repository' pattern:
- Make a new folder in `exercises/exercise04` with your last name (just like the suffix for your notebook file)
- Upload your notebook file, also appropriately named, into that folder
- Upload any other files you make/use, including `.py` and `.csv` files, into that folder, so everything is together in the same place

Ultimately, this will look a bit like this:
```
── exercises
    ├── exercise04
        ├── harvey
            ├── exercise04_harvey.ipynb
            ├── affordable_housing_calcs.py
            ├── affordable_housing.csv
            └── wards_from_2022.csv
```

**NOTE:** Yes, I realize this is a bit redundant because everyone will have copies of the same CSV files. This would never be a good idea for production coding--we would have one `data` directory, and everyone would draw from the same data. However, there are two reasons for all these copies in this case:
1. It's good practice to build a repository with all the parts your code needs to run.
    - In later weeks, when you  _don't_ all have the same data, it won't seem as redundant.
3. Having everything in one folder will make it easy for me to run your code on my computer.

## Hints
- You may want to join the population data _after_ summarizing the affordable housing data (i.e., join populations to sums of units). However, I could also see an approach where you join at the beginning, then aggregate the population column with a method called `first`
"""

# Import your module

# Call your main function

from google.colab import drive
drive.mount('/content/drive')

import os
os.getcwd()

ex_4_path = '/content/drive/MyDrive/aghili'
os.chdir(ex_4_path)

os.path.isfile('affordable_housing.csv')

# Define a function for all the operations and calculations
def housing_analysis(ex_4_path):


    # Import panda and numpy
    import pandas as pd
    # import numpy as np

    # Import the .csv files
    df = pd.read_csv('affordable_housing.csv')

    # Filter rows with units only in
    # Developement Pipeline or Under Construction
    df = df[df['STATUS_PUBLIC'] == ('Pipeline' or 'Under Construction')]

    # Add a column titled AFFORDABLE_UNITS_UP_TO_60_AMI whose values
    # are the total of units up to 60 AMI
    df['AFFORDABLE_UNITS_UP_TO_60_AMI'] = df[[
        'AFFORDABLE_UNITS_AT_0_30_AMI',
        'AFFORDABLE_UNITS_AT_31_50_AMI',
        'AFFORDABLE_UNITS_AT_51_60_AMI']].sum(axis=1)

    # Select relevant columns
    relevant_cols = ['MAR_WARD',
        'STATUS_PUBLIC',
        'AFFORDABLE_UNITS_UP_TO_60_AMI',
        'TOTAL_AFFORDABLE_UNITS']

    df = df[relevant_cols]

    # Group by MAR_WARD
    grouped_df = df.groupby('MAR_WARD')[[
        'AFFORDABLE_UNITS_UP_TO_60_AMI',
        'TOTAL_AFFORDABLE_UNITS']].sum().reset_index()

    # Import the population file
    df_pop_2024 = pd.read_csv('wards_from_2024.csv')

    # Joining two tables with the keys
    # MAR_WARD in first and DP05_0001E in second
    housing_projects_with_pops = pd.merge(grouped_df, df_pop_2024,
        left_on='MAR_WARD', right_on='NAMELSAD')

    housing_projects_with_pops = pd.merge(
        grouped_df,
        df_pop_2024[['NAMELSAD','POP_2024']],
        left_on='MAR_WARD',
        right_on='NAMELSAD')

    # Adding a column whose values are the result of
    # devision between population and the
    housing_projects_with_pops['HOUSING_DISTRIBUTION_RATE'] = grouped_df[
        'TOTAL_AFFORDABLE_UNITS'] / df_pop_2024['POP_2024']

    # Saving the .csv file
    housing_projects_with_pops.to_csv(
        'affordable_housing_with_ward_pops.csv')

    # Loading the created file
    final_answer_full = pd.read_csv(
        'affordable_housing_with_ward_pops.csv')

    # Filtering selected columns
    final_select = final_answer_full.filter([
        'MAR_WARD',
        'AFFORDABLE_UNITS_UP_TO_60_AMI',
        'TOTAL_AFFORDABLE_UNITS',
        'POP_2024',
        'HOUSING_DISTRIBUTION_RATE'])

    # Coloring Min and Max
    color_grouped_df = final_select.style.highlight_max(
        color="green", axis=0).highlight_min(color="red", axis=0)

    # Returning the colored data
    return color_grouped_df

housing_analysis(ex_4_path)